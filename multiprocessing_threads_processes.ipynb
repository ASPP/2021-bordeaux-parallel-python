{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Python\n",
    "\n",
    "Before we get into parallel processing, let's first consider how the type of problems we'll consider are typically solved in a serial context. We'll focus on problems which always have the following form: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "def do_science(x):\n",
    "    \"\"\"For example:\n",
    "    - training a neural network (hyperparameter tuning!)\n",
    "    - getting results from a database\n",
    "    - scraping some websites\n",
    "    - reading files\n",
    "    - sampling monte-carlo style\n",
    "    \"\"\"\n",
    "    return x ** 2  # we don't really do anything ;)\n",
    "\n",
    "results = []\n",
    "input_data = range(10)\n",
    "for x in input_data:\n",
    "    results.append(do_science(x))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This typical structure (or \"smell\" ;) ) is pretty common and most likely all of you have something similar somewhere in your code. It's an excellent opportunity for leveraging parallelism to speed things up. However, first we'll rewrite this code using the builtin `map` function, it makes the code more compact and it will be easier to make this run in parallel. `map` takes a function and an iterable and applies the function to each iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# when applying a function to a bunch of data, maybe you would use list comprehension\n",
    "results = [do_science(x) for x in input_data]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# however, here we use map to later explore its parallel implementations\n",
    "results = map(do_science, input_data)\n",
    "results = list(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(watch out: `map` returns an iterator (->advanced python), you need to convert it to a list explicitly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Compute the cubes of numbers 0..9 using `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = range(10)\n",
    "def cube(x):\n",
    "    # TODO\n",
    "    return x ** 3\n",
    "results = map(cube, input_data)\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- What's the return type of `map`?\n",
    "- Can we also compute the *sum* of numbers `0..9` using map? -> no(t trivially). results of operations depend on each other. this is a contra-indicator for \"embarrassingly parallel\" problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embarassingly-parallel Python\n",
    "This type of problem is referred to as \"embarrassingly parallel\" problems. This indicates that they can be easily parallelized across threads or processes as they do not require interaction while running (they can also be run in serial!). For these types of problems, we can use the builtin `multiprocessing` module. It supports parallel versions of `map` which can be run either in parallel threads or parallel processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel threads\n",
    "We first work with the `ThreadPool` available from the `multiprocessing.pool` module. We assume CPython in which the GIL prevent several threads from executing in parallel. However, for some use cases, in particular those which are **I/O bound**, threading can be very useful. Consider for example obtaining data from some database: you would like to query a couple of measurements, and completing each of these queries may take some processing time on the server. Here we mimick this server-side processing time by merely sleeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(x):\n",
    "    \"\"\"Query your database to retrieve awesome measurements.\"\"\"\n",
    "    print(f'querying data {x} start')\n",
    "    time.sleep(x)  # mimicks (input-dependent) server-side processing\n",
    "    y = x ** 2\n",
    "    print(f'querying data {x} end')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [1, 8, 1.5, 2]  # some dummy queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the builtin `map` function to perform the database query for each item in l:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying data 1 start\n",
      "querying data 1 end\n",
      "querying data 8 start\n",
      "querying data 8 end\n",
      "querying data 1.5 start\n",
      "querying data 1.5 end\n",
      "querying data 2 start\n",
      "querying data 2 end\n",
      "[1, 64, 2.25, 4]\n",
      "CPU times: user 2.76 ms, sys: 7.31 ms, total: 10.1 ms\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = list(map(query_database, input_data))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations?\n",
    "- queries processed in serial, one after the other\n",
    "- total duration is the sum of the duration of each query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use use `ThreadPool` do perform these queries using two threads (here the `processes` argument actually refers to the number of threads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying data 1 start\n",
      "querying data 8 start\n",
      "querying data 1 end\n",
      "querying data 1.5 start\n",
      "querying data 1.5 end\n",
      "querying data 2 start\n",
      "querying data 2 end\n",
      "querying data 8 end\n",
      "CPU times: user 9.06 ms, sys: 8.41 ms, total: 17.5 ms\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = ThreadPool(processes=2)\n",
    "result = pool.map(query_database, input_data)\n",
    "pool.close()\n",
    "\n",
    "#with ThreadPool(processes=2) as pool:  # context manager providing a `ThreadPool` instance\n",
    "#    result = pool.map(query_database, input_data)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations?\n",
    "- results are identical to serial processing of queries; good!\n",
    "- total duration is reduced: work (here: waiting for results) is distributed across threads\n",
    "- allocation: queries are performed in order; thread 0 works on query 0, thread 1 on query 1, thread 0 on the rest while thread 1 is busy with query 1\n",
    "- caveat: optimal number of threads may be difficult to determine (depends on use case! more threads also means more switching!)\n",
    "- caveat: load is not automatically ordered optimally (`ThreadPool` can not know how long each query takes); in our example if long query is the last, total duration increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [1, 1.5, 2, 8]  # some dummy queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ThreadPool(processes=2) as pool:\n",
    "    result = pool.map(query_database, input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "A once-in-a-lifetime opportunity presents itself: you have access to a database holding secret information about ASPP. You can sent queries to it using the `query_secret_aspp_database` function, which expects a single (arbitrary) argument. First, implement a serial version, processing several (4+) queries. Then use the `ThreadPool` to parallelize your code. Time both versions and compare their execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_aspp_database import query_secret_aspp_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO fill me with the serial version\n",
    "queries = ['42', 3.1415, 8162371823.123, 'pelita', 'ajwdiauwdiuahwiduhawdiuhawd']\n",
    "list(map(query_secret_aspp_database, queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO fill me with the parallel version\n",
    "with ThreadPool(processes=2) as pool:\n",
    "    result = pool.map(query_secret_aspp_database, queries)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread-parallel(?) number crunching\n",
    "Now let's consider a compute-intense number-crunching task, for example tuning hyperparameters our fancy neural network model to squeeze out the additional 0.0002% increase in accuracy. Here we mimick the training by merely counting down from a large number (let's avoid cognitive overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    \"\"\"Train your favourite neural network model.\"\"\"\n",
    "    print(f'training with {x} start')\n",
    "    n = x * 2e7  # mimick compute-intense training\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "    y = x ** 2\n",
    "    print(f'training with {x} end')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [1, 8, 1.5, 2]  # some dummy simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, first, we use the builtin `map` function to perform the number crunching serially for each item in l:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1 start\n",
      "training with 1 end\n",
      "training with 8 start\n",
      "training with 8 end\n",
      "training with 1.5 start\n",
      "training with 1.5 end\n",
      "training with 2 start\n",
      "training with 2 end\n",
      "[1, 64, 2.25, 4]\n",
      "CPU times: user 27.3 s, sys: 0 ns, total: 27.3 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = list(map(train_neural_network, input_data))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- number crunching causes high CPU load (surprise! ;) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use again use `ThreadPool` do parallelize this work using two threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1 starttraining with 8 start\n",
      "\n",
      "training with 1 end\n",
      "training with 1.5 start\n",
      "training with 1.5 end\n",
      "training with 2 start\n",
      "training with 2 end\n",
      "training with 8 end\n",
      "[1, 64, 2.25, 4]\n",
      "CPU times: user 26.3 s, sys: 0 ns, total: 26.3 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ThreadPool(processes=2) as pool:\n",
    "    result = pool.map(train_neural_network, input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations?\n",
    "- runtime (almost) identical to serial execution: GIL prevents simultaneous number crunching. :'(\n",
    "\n",
    "Questions:\n",
    "- what is the return type of `pool.map`? -> list\n",
    "- why is this different than the return type of `map`? -> normal map: delayed execution is desired, with pool you want to do the computation immediately (and in parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel processes\n",
    "For such tasks, we use the `ProcessPool`. In contrast to the `ThreadPool` this distributes work across multiple processes running separate instances of the Python interpreter. This allows you to circumvent the limitations of the GIL and achieve truly parallel code execution. For use cases which are **compute bound**, it is an excellent, simple-to-use option. As already introduced above, these use cases may include numerical simulations, sampling methods etc. Unfortunately, using multiple processes introduces some downsides, such as some overhead (time & memory) for launching processes and increased memory consumption (e.g., duplication of data; warning: depends on implementation and use case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool as ProcessPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1 start\n",
      "training with 8 start\n",
      "training with 1 end\n",
      "training with 1.5 start\n",
      "training with 1.5 end\n",
      "training with 2 start\n",
      "training with 2 end\n",
      "training with 8 end\n",
      "[1, 64, 2.25, 4]\n",
      "CPU times: user 40.9 ms, sys: 0 ns, total: 40.9 ms\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ProcessPool(processes=2) as pool:  # context manager providing a `Pool` instance\n",
    "    result = pool.map(train_neural_network, input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations?\n",
    "- results are identical to serial and threaded execution; good!\n",
    "- runtime is reduced compared to both serial and threaded execution\n",
    "- increased CPU load on multiple cores\n",
    "- caveat: as before, no automatic load balancing, tasks are executed in order\n",
    "\n",
    "Questions:\n",
    "- What is the fundamental difference between threads and processes? -> memory shared across threads, by default not across processes\n",
    "- How does the data get from the main thread to the worker thread? -> shared memory (direct access)\n",
    "- How does the data get from the main process to the worker process? -> communication (sending serialized data (in Python: pickle -> problems with stuff that's not picklable), or set up shared memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel speedup\n",
    "So how much faster does my code become when I'm increasing the number of processes? Here we investigate the relative speedup ($T_\\textrm{parallel} / T_\\textrm{serial}$) for an increasing number of processes. We use the same compute-bound function as before, but remove some of the annoying output and make it a bit shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.043039798736572266,\n",
       " 0.03096604347229004,\n",
       " 0.04002118110656738,\n",
       " 0.04499959945678711,\n",
       " 0.051397085189819336,\n",
       " 0.05700969696044922,\n",
       " 0.07579755783081055,\n",
       " 0.07624220848083496]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def train_neural_network(x):\n",
    "    \"\"\"Train your favourite neural network model.\"\"\"\n",
    "    n = x * 1e6  # mimick compute-intense training\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "    y = x ** 2\n",
    "    return y\n",
    "\n",
    "\n",
    "input_data = [2] * 16  # some dummy simulations of equal duration\n",
    "times = []\n",
    "n_processes = np.arange(1, 9)\n",
    "for n in n_processes:\n",
    "    t0 = time.time()\n",
    "    with ProcessPool(processes=n) as pool:\n",
    "        result = pool.map(train_neural_network, input_data)\n",
    "    times.append(time.time() - t0)\n",
    "\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7c016f69d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "times = np.array(times)\n",
    "fig, axes = plt.subplots()\n",
    "axes.plot(n_processes, 1.0 * n_processes, color='k', linestyle='--', label='ideal')\n",
    "axes.plot(n_processes, times[0] / times, marker='o', label='measured')\n",
    "axes.set_xlabel(r'$n$ processes')\n",
    "axes.set_ylabel('relative speedup')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "- perfect speedup with 2-3 processes, (on some machines) good speedup until ~4-5 processes with decreasing benefits\n",
    "- no (significant) benefits for more processes\n",
    "- rule of thumb: benefits up to number of cores (OS also needs some compute: context switching; also hyperthreading does not seem to work well in my experience)\n",
    "\n",
    "Questions:\n",
    "- Can we combine `ProcessPools` with `ThreadPools` in the worker processes? -> yes, but benefit depends on use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Exercise\n",
    "Implement your own compute-bound function. Compare it's runtime for different numbers of processes, similar as in our example above. In particular investigate the case of \"fast\" compute-bound functions. Discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (2696325191.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_32513/2696325191.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    input_data = …   # TODO: replace with meaningful input to your function\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "def crunch_numbers(x):\n",
    "    pass  # TODO replace with some number crunching\n",
    "\n",
    "input_data = …   # TODO: replace with meaningful input to your function\n",
    "times = []\n",
    "for n_processes in range(1, 9):\n",
    "    t0 = time.time()\n",
    "    with ProcessPool(processes=n_processes) as pool:\n",
    "        results = pool.map(crunch_numbers, input_data)\n",
    "    times.append(time.time() - t0)\n",
    "\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- We get got a speedup. Could we get a slowdown?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing, but with numpy\n",
    "Let's consider a similar example as before (number crunching!) but now we leverage additional libraries to speed up the computation. In this example we will use numpy to perform maxtrix multiplications (dot products). To be fast, numpy (and many other libraries) rely on implementations of computationally expensive function in *compiled* language (e.g., C++). This is great, but unfortunately may interfere with multiprocessing at the Python level, since the compiled function can leverage parallelization too! To illustrate this point, let's consider a compute-intense function which just performs matrix multiplications. Again, we will compare the runtime of the serial with the parallel version (using multiple processes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from multiprocessing.pool import Pool as ProcessPool\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def train_neural_network(m):\n",
    "    \"\"\"Train your favourite neural network model.\"\"\"\n",
    "    y = np.mean(np.dot(m, m))  # mimick compute-intense training\n",
    "    return y\n",
    "\n",
    "n = 3_000\n",
    "# generate some random matrices as input\n",
    "input_data = [np.random.randn(n, n), np.random.randn(n, n), np.random.randn(n, n), np.random.randn(n, n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.87 s, sys: 31.8 ms, total: 5.9 s\n",
      "Wall time: 5.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02260239009863062,\n",
       " 0.019099992856037504,\n",
       " 0.0155115103447624,\n",
       " -0.003729112933788689]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = list(map(train_neural_network, input_data))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02260239009863062, 0.019099992856037504, 0.0155115103447624, -0.003729112933788689]\n",
      "CPU times: user 150 ms, sys: 194 ms, total: 344 ms\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ProcessPool(processes=4) as pool:\n",
    "    result = pool.map(train_neural_network, input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Duration does not change (might actually be a bit longer) if we use multiple processes.\n",
    "- High load on all CPUs *even for the serial computation*. -> numpy parallelizes at a lower level\n",
    "- Solution: limit the number of threads numpy can use via the `OMP_NUM_THREADS` environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "https://www.youtube.com/watch?v=AG1soUh4-nU\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
